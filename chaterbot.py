# -*- coding: utf-8 -*-
"""Chaterbot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j06iDIh_z2Sjwqv5Y2RbYVCVMyIMXQh0
"""

pip install chatterbot

pip install spacy

from chatterbot import ChatBot
from chatterbot.trainers import ListTrainer

!python -m spacy download en

# Creamos una nueva instancia de Chatbot
bot = ChatBot('Mi primer bot')

#Entrenamiento en forma de lista
trainer = ListTrainer(bot)
#Cada elemento de la lista como una posible
#respuesta a su predecesor en la lista.
trainer.train([
 "Hi there!",
 "Hello",
])
trainer.train([
 "Greetings!",
 "Hello",
])

print('Escribe algo para comenzar...')

# El siguiente bucle es infinito
while True:
    try:
        user_input = input()
        bot_response = bot.get_response(user_input)
        print('Bot says: ', bot_response)
    # Presiona ctrl-c o ctrl-d para salir
    except (KeyboardInterrupt, EOFError, SystemExit):
        break

#Instalación de transformers. Librería que nos
#provee de modelos de audio, video, texto, etc.
!pip3 install transformers

from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# Selección del modelo
# model_name = "microsoft/DialoGPT-large"
model_name = "microsoft/DialoGPT-medium"
# model_name = "microsoft/DialoGPT-small"

# Carga del tokenizador y del modelo
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name)

# Tenemos 5 interacciones con el bot
for step in range(5):
    # Entrada del usuario
    text = input(">> Tu: ")

    # Codifica la entrada y añade el token de finalización
    input_ids = tokenizer.encode(text + tokenizer.eos_token, return_tensors="pt")

    # Concatena la última entrada del usuario al historial del chat (si existe)
    bot_input_ids = torch.cat([chat_history_ids, input_ids], dim=-1) if step > 0 else input_ids

    # Genera la respuesta del bot
    chat_history_ids = model.generate(
        bot_input_ids,
        max_length=1000,
        pad_token_id=tokenizer.eos_token_id,
    )

    # Decodifica y muestra la respuesta del bot
    output = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)
    print(f"AI_CHATBOT: {output}")

